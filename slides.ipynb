{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<center><h2><b>CryptoSight</b></h2></center>\n",
    "<center><i>Il lungo e tortuoso viaggio nelle inter-compatibilit√†</i></center>\n",
    "<center><img src=\"./docs/images/dashboard.png\" alt=\"CryptoSight\" width=\"700\"/></center>"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Goal üíª\n",
    "\n",
    "CryptoSight √® il progetto sviluppato per il corso di *Technologies for Advanced Programming* dell'UniCT. \n",
    "\n",
    "L'obbiettivo principale del progetto √® mettere in pratica gli strumenti spiegati nel corso al fine di creare una pipeline completa di elaborazione, che vada dalla *Data Ingestion* alla visualizzazione dei dati per l'utente finale attraverso *OpenSearch Dashboard*\n",
    "\n",
    "CryptoSight si incentra sul tracking di alcune statistiche legato al mondo delle cryptomonete: il cambio, volume, unit√† di circolazione, capitalizzazione di mercato di una piccola selezione di monete.\n",
    "\n",
    "Le monete tracciate sono: Bitcoin, Ethereum, XRP, Cardano, Binance Coin, Dogecoin.\n",
    "\n",
    "La pipeline presenta una piccola applicazione di *Machine Learning* riguardante la *previsione* del cambio delle monete."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## La pipeline üëÄ\n",
    "<center><img src=\"./docs/images/pipeline.png\" alt=\"pipeline\"/></center>\n",
    "\n",
    "<center><b>L'idea di usare OpenSearch mi √® costata la sanit√† mentale, ma √® andata</b></center>"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Source ‚ö†Ô∏è\n",
    "\n",
    "\n",
    "Per la realizzazione del progetto si ci √® basato su una piattaforma di tracking denominata *CoinGecko*. \n",
    "<center><img src=\"./docs/images/coingecko.jpg\" alt=\"I am poor\" width=\"300\"/></center>\n",
    "\n",
    "La piattaforma offre una serie di piani... molto costosi. Mi sono limitato all'utilizzo del piano gratuito che offre un massimale di 50 richieste/minuto.\n",
    "\n",
    "<center><img src=\"./docs/images/expensive.jpg\" alt=\"I am poor\" width=\"400\"/></center>"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Ingestion üîß \n",
    "<center><img src=\"./docs/images/logstash.png\" alt=\"Logstash\" width=\"400\"/></center>\n",
    "Con il termine *Data Ingestion* si intende il processo con il quale vengono acquisiti e importati i dati per uso immediato o per archiviazione in un database.\n",
    "\n",
    "Per il progetto si √® scelto di utilizzare Logstash per la sua facilit√† di utilizzo e integrazione con gli altri componenti della pipeline. <i>In particolare l'integrazione con OpenSearch <b>dovrebbe</b> essere garantita da Logstash FOSS con OS Plugin... <b>ma la vita non √® mai semplice.</b></i>\n",
    "\n",
    "Logstash sfrutta il plugin *http_poller* come canale input per eseguire uno *streaming* (fetch real-time) di *dati strutturati* (contenuto in un comunissimo formato JSON) verso Kafka attraverso il plugin di output dedicato"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logstash in dettaglio\n",
    "\n",
    "L'http_poller esegue periodicamente la chiamata al seguente indirizzo:\n",
    "\n",
    "> https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&ids=bitcoin%2Cethereum%2Cdogecoin%2Ccardano%2Ctether%2Cbinancecoin%2Cripple&order=market_cap_desc&per_page=100&page=1&sparkline=false\n",
    "\n",
    "Questa chiamata ritorna un *JSONArray* che mediante l'utilizzo del *codec json* viene spacchettato in *singoli messaggi* del topic di Kafka"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Streaming e Stream Processing üî®\n",
    "\n",
    "<center><img src=\"./docs/images/kafka.jpeg\" alt=\"Kafka\" width=\"400\"/></center>\n",
    "\n",
    "Basandoci sulla filosofia MOM (*Middleware orientato ai messaggi*) e lo *Stream Processing*, si impiega Kafka e uno KafkaStream per elaborare i messaggi *\"raw\"* ricevuto da Logstash. I dati vengono *puliti da informazioni non utilizzate e viene immesso un fattore di variazione per scopi didattici*.\n",
    "\n",
    "Si √® preferito eseguito la pulizia dei dati su KafkaStream anzich√® su Logstash, mediante la funzionalit√† *filter*, poich√® per possibili ampliazioni future baster√† metter mano solamente sul KafkaStream. Ci√≤, in aggiunta alla persistenza dello storage di Kafka, ci permette di poter variare l'elaborazione dei dati senza dover rinunciare a tutti i dati raccolti fino a quel momento."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inizia la sofferenza üò¢\n",
    "\n",
    "<center><img src=\"./docs/images/esos.jpg\" alt=\"ESOS\" width=\"400\"/></center>\n",
    "\n",
    "Nel corso di TAP abbiamo visto e usato *ElasticSearch*, un motore di analisi e ricerca dei dati, e *Kibana*, un applicazione front-end grauito che collegandosi a ElasticSearch permette l'utilizzo dei dati sotto forma di grafici o altre funzionalit√† pi√π complesse.\n",
    "\n",
    "Nel mentre per√≤... **ElasticSearch ha fatto l'avido cambiando i termini della propria licenza** (*per maggiori informazioni, leggersi le slides sull'argomento presenti sul mio GitHub*), ci√≤ ha portato alla nascit√† di un fork di entrambe le piattaforma sopracitate:\n",
    "\n",
    "- ElasticSearch => OpenSearch\n",
    "- Kibana => OpenSearch-Dashboards\n",
    "\n",
    "**Credo che il meme indichi chiaramente la strada (\"strada\", l'avete capita?) che ho intrapreso... non l'avessi mai fatto!**"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kafka to OpenSearch üì¶\n",
    "\n",
    "<center><img src=\"./docs/images/opensearch.jpg\" alt=\"OS\" width=\"400\"/></center>\n",
    "\n",
    "OpenSearch ha rivoluzionato un pochetto le modalit√† di comunicazione con gli altri componenti. In particoliamo evidenzio:\n",
    "- OpenSearch nella comunicazione utilizza il proprio versioning, che parte da 1.0, anzich√© quello di Elastic, che attualmente sta alla 7.15;\n",
    "- La comunicazione HTTP anomina √® stata deprecata, ora √® necessario connettersi tramite HTTPS (quindi avere a che fare con certificati SSL) e fornire delle credenziali;\n",
    "- La porta del performance analyzer √® stata cambiata;\n",
    "- Non presenta il plugin per le operazioni senza autenticazione;\n",
    "\n",
    "### Quindi?"
   ],
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Le scelte, quelle importanti! üò∂\n",
    "\n",
    "<center><img src=\"./docs/images/kafkaingestion.jpg\" alt=\"kafka is hungry\" width=\"300\"/></center>\n",
    "\n",
    "Guardando le scelte implementative degli altri colleghi ho visto una tendenza ad usare:\n",
    "- Kafka Connect to ElasticSearch\n",
    "- Un Kafka Consumer ad hoc\n",
    "\n",
    "Dati i problemi sopracitati, OpenSearch √® venuto incontro alla community fornendo una distribuzione di *Logstash FOSS con un plugin output dedicato a OpenSearch*.\n",
    "\n",
    "**La scelta finale √® stata immediata.**"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I primi grafici! üìà\n",
    "\n",
    "<center><img src=\"./docs/images/opendashboards.jpg\" alt=\"I need data!\" width=\"300\"/></center>\n",
    "\n",
    "Possiamo loggare su OpenSearch Dashboards per creare grafici!\n",
    "\n",
    "<center><img src=\"./docs/images/marketcap.png\" alt=\"Circles\" width=\"300\"/> <img src=\"./docs/images/volume.png\" alt=\"Squares\" width=\"300\"/></center>"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Siamo a buon punto! ‚òïÔ∏è\n",
    "\n",
    "<center><img src=\"./docs/images/prefail.jpg\" alt=\"I need data!\" width=\"500\"/></center>"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spark e Machine Learning ‚ú®\n",
    "\n",
    "Siamo nel 2021, il termine \"Machine Learning\" fa gola a tutti... infiliamo un p√≤ di ML nella pipeline!\n",
    "\n",
    "Come gi√† detto precedentemente, la pipeline svolte un'operazione di machine learning per *l'arricchimento dei dati attraverso una predizione del cambio futuro*\n",
    "\n",
    "Viene attuato uno Spark Streaming con una finestra di 1 minuti per predire i successivi valori.\n",
    "\n",
    "### Dove sta il problema?"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spark & OpenSearch ‚ö†Ô∏è\n",
    "\n",
    "<center><img src=\"./docs/images/sparkerror.jpg\" alt=\"Ready\"/></center>\n",
    "\n",
    "I cambiamenti di OpenSearch hanno creato non pochi grattacapi per quanto rigurada la comunicazione fra PySpark e OpenSearch.\n",
    "\n",
    "- L'obbligo di una connessione HTTPS ha richieste molti pi√π parametri del normale ElasticSearch.\n",
    "- L'override del versioning causava problemi di ambiguit√† nel comportamento di Spark.\n",
    "\n",
    "Per l'ultimo problema OpenSearch ha fornito una soluzione.\n",
    "\n",
    "> compatibility.override_main_response_version=true\n",
    "\n",
    "\n",
    "### E' fatta allora?"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<center><img src=\"./docs/images/versioning.jpg\" alt=\"Home\"/></center>\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cos'√® successo?\n",
    "\n",
    "Abilitando la **compatibility mode** di OpenSearch si √® rotto il supporto per **Logstash FOSS con plugin OS*\n",
    "\n",
    "<center><img src=\"./docs/images/compatibility.png\" alt=\"Home\"/></center>\n",
    "Ma ci√≤ non era stato detto..."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's start!\r\n",
    "\r\n",
    "> docker-compose up -d"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Thank you for your attention\n",
    "\n"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}